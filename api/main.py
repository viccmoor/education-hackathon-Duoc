from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
import pandas as pd
from pathlib import Path
from contextlib import asynccontextmanager
import sys
import os
from dotenv import load_dotenv

# Configurar path para importar m√≥dulos
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.model import DesercionPredictor
from src.features import create_features

# Cargar variables de entorno
load_dotenv()

# Variable global para el modelo
MODEL_PATH = os.path.join("..", "models", "desercion_predictor.joblib")
model: Optional[DesercionPredictor] = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestiona el ciclo de vida de la aplicaci√≥n (startup/shutdown)."""
    global model
    
    # Startup
    print("\n" + "="*60)
    print("üöÄ INICIANDO API DE PREDICCI√ìN DE DESERCI√ìN")
    print("="*60)
    
    try:
        if os.path.exists(MODEL_PATH):
            model = DesercionPredictor.load(str(MODEL_PATH))
            print(f"‚úÖ Modelo cargado desde {MODEL_PATH}")
            print(f"   Features: {len(model.feature_names)}")
        else:
            print(f"‚ö†Ô∏è  Modelo no encontrado en {MODEL_PATH}")
            print("   Ejecuta 'python src/train.py' para entrenar el modelo")
    except Exception as e:
        print(f"‚ùå Error cargando modelo: {e}")
        model = None
    
    # Verificar OpenAI API Key
    if os.getenv("OPENAI_API_KEY"):
        print("‚úÖ OpenAI API Key configurada")
    else:
        print("‚ö†Ô∏è  OpenAI API Key no configurada - endpoint /coach no disponible")
    
    print("="*60 + "\n")
    
    yield  # Aplicaci√≥n en ejecuci√≥n
    
    # Shutdown
    print("\nüõë Cerrando API...")

# Inicializar FastAPI con lifespan
app = FastAPI(
    title="API Predicci√≥n Deserci√≥n Estudiantil - Duoc UC",
    description="Sistema de predicci√≥n de riesgo de deserci√≥n y coaching acad√©mico con LLM",
    version="1.0.0",
    lifespan=lifespan
)

# Configurar CORS para desarrollo
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producci√≥n, especificar dominios permitidos
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === MODELOS DE DATOS ===

class StudentData(BaseModel):
    """Datos del estudiante para predicci√≥n."""
    promedio_asistencia: Optional[float] = Field(None, ge=0, le=100, description="Promedio de asistencia (0-100%)")
    porcentaje_aprobacion: Optional[float] = Field(None, ge=0, le=1, description="Porcentaje de aprobaci√≥n (0-1)")
    promedio_notas: Optional[float] = Field(None, ge=1, le=7, description="Promedio de notas (1-7)")
    tasa_2020: Optional[float] = Field(None, ge=0, le=1, description="Tasa hist√≥rica (0-1)")
    estudiantes_retirados: Optional[int] = Field(None, ge=0, description="Estudiantes retirados en el curso")
    porcentaje_retiro: Optional[float] = Field(None, ge=0, le=1, description="Porcentaje de retiro (0-1)")
    total_estudiantes: Optional[int] = Field(None, ge=1, description="Total de estudiantes en el curso")
    a√±o: Optional[int] = Field(None, ge=2020, le=2030, description="A√±o acad√©mico")
    
    class Config:
        json_schema_extra = {
            "example": {
                "promedio_asistencia": 75.0,
                "porcentaje_aprobacion": 0.65,
                "promedio_notas": 5.0,
                "tasa_2020": 0.05,
                "estudiantes_retirados": 15,
                "porcentaje_retiro": 0.03,
                "total_estudiantes": 500,
                "a√±o": 2024
            }
        }

class StudentPayload(BaseModel):
    """Datos del estudiante para predicci√≥n."""
    promedio: float = Field(..., ge=1, le=7, description="Promedio de notas (1-7)")
    asistencia: float = Field(..., ge=0, le=100, description="Porcentaje de asistencia (0-100%)")
    edad: int = Field(..., ge=10, le=100, description="Edad del estudiante")
    sexo: str = Field(..., description="Sexo del estudiante (M/F u otro)")
    asignatura: str = Field(..., description="Nombre de la asignatura")
    establecimiento: str = Field(..., description="Nombre del establecimiento educativo")

    class Config:
        schema_extra = {
            "example": {
                "promedio": 5.5,
                "asistencia": 85,
                "edad": 20,
                "sexo": "M",
                "asignatura": "Programaci√≥n",
                "establecimiento": "Duoc UC Sede Maip√∫"
            }
        }

class PredictionRequest(BaseModel):
    """Solicitud de predicci√≥n."""
    payload: StudentPayload

class PredictionResponse(BaseModel):
    """Respuesta de predicci√≥n."""
    riesgo_desercion: float = Field(..., ge=0, le=1, description="Probabilidad de deserci√≥n (0-1)")
    nivel_riesgo: str = Field(..., description="BAJO, MEDIO o ALTO")
    recomendacion: str = Field(..., description="Recomendaci√≥n textual")
    confianza: str = Field(..., description="Nivel de confianza de la predicci√≥n")
    drivers: list[dict] = Field(
        ..., description="Factores que influyen en la predicci√≥n: feature, value e importancia"
    )

class CoachRequest(BaseModel):
    """Solicitud de coaching con LLM."""
    student_data: Dict[str, Any]
    question: str = Field(..., description="Pregunta del estudiante o docente")
    context: Optional[str] = Field(None, description="Contexto adicional")

class CoachResponse(BaseModel):
    """Respuesta de coaching."""
    answer: str = Field(..., description="Respuesta del coach virtual")
    riesgo_detectado: Optional[float] = Field(None, description="Riesgo detectado si aplica")

# === ENDPOINTS ===

@app.get("/")
async def root():
    """Endpoint ra√≠z con informaci√≥n de la API."""
    return {
        "message": "API de Predicci√≥n de Deserci√≥n Estudiantil - Duoc UC",
        "version": "1.0.0",
        "status": "online",
        "model_loaded": model is not None,
        "endpoints": {
            "GET /": "Informaci√≥n de la API",
            "GET /health": "Estado de la API y modelo",
            "POST /predict": "Predicci√≥n de riesgo de deserci√≥n",
            "POST /coach": "Coach virtual con LLM (requiere OpenAI API key)",
            "GET /stats": "Estad√≠sticas del modelo",
            "GET /docs": "Documentaci√≥n interactiva Swagger",
            "GET /redoc": "Documentaci√≥n ReDoc"
        }
    }

@app.get("/health")
async def health():
    """Verifica el estado de la API y el modelo."""
    openai_configured = bool(os.getenv("OPENAI_API_KEY"))
    
    return {
        "status": "healthy",
        "model": {
            "loaded": model is not None,
            "path": str(MODEL_PATH),
            "exists": MODEL_PATH.exists(),
            "features_count": len(model.feature_names) if model else 0
        },
        "services": {
            "openai_coach": "available" if openai_configured else "not_configured"
        }
    }

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """
    Predice el riesgo de deserci√≥n de un estudiante.
    
    Retorna:
    - riesgo_desercion: Probabilidad entre 0 y 1
    - nivel_riesgo: BAJO (<0.5), MEDIO (0.5-0.8), ALTO (>0.8)
    - recomendacion: Texto con recomendaciones seg√∫n el nivel de riesgo
    - confianza: Nivel de confianza basado en datos disponibles
    """
    if model is None:
        raise HTTPException(
            status_code=503,
            detail="Modelo no disponible. Ejecuta 'python src/train.py' para entrenar el modelo."
        )
    
    try:
        # Convertir a DataFrame
        data_dict = request.payload.dict(exclude_none=True)
        
        if not data_dict:
            raise HTTPException(
                status_code=400,
                detail="Debe proporcionar al menos un campo de datos del estudiante"
            )
        
        df = pd.DataFrame([data_dict])
        
        # Crear features
        X = create_features(df)
        
        # Calcular confianza basada en datos disponibles
        campos_disponibles = len(data_dict)
        campos_totales = len(StudentData.model_fields)
        confianza_pct = campos_disponibles / campos_totales
        
        if confianza_pct > 0.7:
            confianza = "ALTA"
        elif confianza_pct > 0.4:
            confianza = "MEDIA"
        else:
            confianza = "BAJA"
        
        # Predecir
        prob = float(model.predict_proba(X)[0])
        
        # Clasificar nivel de riesgo
        if prob < 0.5:
            nivel = "BAJO"
            recomendacion = (
                "‚úÖ El estudiante presenta bajo riesgo de deserci√≥n. "
                "Mantener seguimiento regular y reforzar h√°bitos positivos de estudio."
            )
        elif prob < 0.8:
            nivel = "MEDIO"
            recomendacion = (
                "‚ö†Ô∏è El estudiante presenta riesgo medio de deserci√≥n. "
                "Recomendaciones:\n"
                "‚Ä¢ Reuni√≥n con tutor acad√©mico para identificar causas\n"
                "‚Ä¢ Plan de mejora en asistencia y/o notas\n"
                "‚Ä¢ Apoyo psicopedag√≥gico si es necesario\n"
                "‚Ä¢ Seguimiento quincenal del progreso"
            )
        else:
            nivel = "ALTO"
            recomendacion = (
                "üö® ALERTA: Riesgo alto de deserci√≥n - Acci√≥n inmediata requerida\n\n"
                "Plan de intervenci√≥n urgente:\n"
                "1. Entrevista individual con el estudiante (esta semana)\n"
                "2. Evaluar situaci√≥n personal/familiar/econ√≥mica\n"
                "3. Plan de intervenci√≥n personalizado con metas claras\n"
                "4. Seguimiento semanal obligatorio\n"
                "5. Coordinaci√≥n con Bienestar Estudiantil\n"
                "6. Considerar opciones de apoyo financiero/becas\n"
                "7. Vincular con tutor√≠as acad√©micas especializadas"
            )

        drivers = []
        for col in X.columns:
            val = X[col].iloc[0]
            importance = abs(val - X[col].mean())
            drivers.append({
                "feature": str(col),
                "value": float(val),
                "importance": float(importance)
            })

        drivers = sorted(drivers, key=lambda x: x["importance"], reverse=True)[:5]

        return PredictionResponse(
            riesgo_desercion=prob,
            nivel_riesgo=nivel,
            recomendacion=recomendacion,
            confianza=confianza,
            drivers=drivers
        )
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"Error en predicci√≥n: {str(e)}\nVerifica que los datos est√©n en el formato correcto."
        )

@app.post("/coach", response_model=CoachResponse)
async def coach(request: CoachRequest):
    """
    Coach virtual con LLM para estudiantes y docentes.
    
    Requiere OPENAI_API_KEY en .env
    """
    openai_key = os.getenv("OPENAI_API_KEY")
    
    if not openai_key:
        raise HTTPException(
            status_code=503,
            detail="OpenAI API key no configurada. A√±ade OPENAI_API_KEY al archivo .env"
        )
    
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key=openai_key)
        
        # Predecir riesgo si hay datos suficientes y modelo disponible
        riesgo = None
        if model and request.student_data:
            try:
                df = pd.DataFrame([request.student_data])
                X = create_features(df)
                riesgo = float(model.predict_proba(X)[0])
            except Exception as e:
                print(f"No se pudo calcular riesgo en /coach: {e}")
        
        # Construir prompt
        context_str = f"\nContexto adicional: {request.context}" if request.context else ""
        riesgo_str = ""
        if riesgo is not None:
            nivel = "ALTO" if riesgo > 0.8 else "MEDIO" if riesgo > 0.5 else "BAJO"
            riesgo_str = f"\n\nüéØ Riesgo de deserci√≥n detectado: {riesgo:.1%} ({nivel})"
        
        system_prompt = """Eres un coach acad√©mico experto de Duoc UC especializado en prevenci√≥n de deserci√≥n estudiantil.

Tu rol es:
1. Brindar apoyo emocional y motivacional con empat√≠a
2. Sugerir estrategias de estudio y organizaci√≥n concretas
3. Identificar recursos institucionales disponibles (tutor√≠as, becas, apoyo psicol√≥gico)
4. Ofrecer consejos pr√°cticos y accionables
5. Detectar se√±ales de riesgo y sugerir intervenciones tempranas

Principios:
- Ser emp√°tico y comprensivo
- Ofrecer soluciones realistas y alcanzables
- Enfocarte en fortalezas del estudiante
- Promover autonom√≠a y autorregulaci√≥n
- Conectar con recursos institucionales cuando sea necesario

Responde de forma concreta, orientada a la acci√≥n y sin tecnicismos innecesarios."""
        
        user_prompt = f"""Pregunta del estudiante/docente: {request.question}

Datos del estudiante: {request.student_data}{context_str}{riesgo_str}

Por favor, proporciona una respuesta √∫til, personalizada y emp√°tica."""
        
        # Llamar a OpenAI
        response = client.chat.completions.create(
            model=os.getenv("LLM_MODEL", "gpt-4o-mini"),
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=600
        )
        
        answer = response.choices[0].message.content
        
        return CoachResponse(
            answer=answer,
            riesgo_detectado=riesgo
        )
    
    except ImportError:
        raise HTTPException(
            status_code=500,
            detail="Librer√≠a 'openai' no instalada. Ejecuta: pip install openai"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"Error en coaching: {str(e)}"
        )

@app.get("/stats")
async def stats():
    """Estad√≠sticas del modelo (requiere modelo cargado)."""
    if model is None:
        raise HTTPException(
            status_code=503, 
            detail="Modelo no disponible. Ejecuta 'python src/train.py' primero."
        )
    
    try:
        return {
            "model_info": {
                "type": type(model.model).__name__,
                "features_count": len(model.feature_names),
                "features": model.feature_names,
                "has_scaler": model.scaler is not None,
                "has_imputer": model.imputer is not None
            },
            "model_path": str(MODEL_PATH),
            "model_size_bytes": MODEL_PATH.stat().st_size if MODEL_PATH.exists() else 0
        }
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"Error obteniendo stats: {str(e)}"
        )

# Endpoint adicional para demo
@app.get("/demo")
async def demo():
    """Ejemplos de uso de la API."""
    return {
        "message": "Ejemplos de uso de la API",
        "examples": {
            "predict": {
                "url": "/predict",
                "method": "POST",
                "payload": {
                    "payload": {
                        "promedio_asistencia": 70.0,
                        "porcentaje_aprobacion": 0.60,
                        "promedio_notas": 4.5,
                        "tasa_2020": 0.08
                    }
                }
            },
            "coach": {
                "url": "/coach",
                "method": "POST",
                "payload": {
                    "student_data": {
                        "promedio_asistencia": 65.0,
                        "promedio_notas": 4.2
                    },
                    "question": "Me cuesta concentrarme en clases, ¬øqu√© puedo hacer?"
                }
            }
        },
        "docs_url": "/docs",
        "redoc_url": "/redoc"
    }
