from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
import pandas as pd
from pathlib import Path
from contextlib import asynccontextmanager
import sys
import os
import json
from dotenv import load_dotenv

# Configurar path para importar m√≥dulos
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.model import DesercionPredictor
from src.features import create_features
from src.rag import RendimientoRAG

# Cargar variables de entorno
load_dotenv()

# Variables globales
MODEL_PATH = Path("models/desercion_predictor.joblib")
METRICS_PATH = Path("models/metrics.json")
THRESHOLD_PATH = Path("models/threshold.txt")

model: Optional[DesercionPredictor] = None
rag: Optional[RendimientoRAG] = None
THRESHOLD_OVERRIDE: Optional[float] = None

def current_threshold() -> float:
    """Obtiene el threshold actual (override o desde archivo)."""
    if THRESHOLD_OVERRIDE is not None:
        return THRESHOLD_OVERRIDE
    
    if THRESHOLD_PATH.exists():
        try:
            with open(THRESHOLD_PATH, 'r') as f:
                return float(f.read().strip())
        except Exception:
            pass
    
    return 0.5  # Default

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestiona el ciclo de vida de la aplicaci√≥n (startup/shutdown)."""
    global model, rag
    
    # Startup
    print("\n" + "="*60)
    print("üöÄ INICIANDO API DE PREDICCI√ìN DE DESERCI√ìN")
    print("="*60)
    
    try:
        if MODEL_PATH.exists():
            model = DesercionPredictor.load(str(MODEL_PATH))
            print(f"‚úÖ Modelo cargado desde {MODEL_PATH}")
            print(f"   Features: {len(model.feature_names)}")
        else:
            print(f"‚ö†Ô∏è  Modelo no encontrado en {MODEL_PATH}")
            print("   Ejecuta 'python src/train.py' para entrenar el modelo")
    except Exception as e:
        print(f"‚ùå Error cargando modelo: {e}")
        model = None
    
    # Cargar RAG
    print("\nüîç Inicializando sistema RAG...")
    try:
        rag = RendimientoRAG(max_rows=50_000)
    except Exception as e:
        print(f"‚ö†Ô∏è RAG no disponible: {e}")
        rag = None
    
    # Verificar OpenAI API Key
    if os.getenv("OPENAI_API_KEY"):
        print("‚úÖ OpenAI API Key configurada")
    else:
        print("‚ö†Ô∏è  OpenAI API Key no configurada - endpoint /coach no disponible")
    
    print("="*60 + "\n")
    
    yield  # Aplicaci√≥n en ejecuci√≥n
    
    # Shutdown
    print("\nüõë Cerrando API...")

# Inicializar FastAPI con lifespan
app = FastAPI(
    title="API Predicci√≥n Deserci√≥n Estudiantil - Duoc UC",
    description="Sistema de predicci√≥n de riesgo de deserci√≥n y coaching acad√©mico con LLM",
    version="1.0.0",
    lifespan=lifespan
)

# Configurar CORS para desarrollo
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producci√≥n, especificar dominios permitidos
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === MODELOS DE DATOS ===

class StudentData(BaseModel):
    """Datos del estudiante para predicci√≥n."""
    promedio: Optional[float] = Field(None, ge=1, le=7, description="Promedio general (1-7)")
    asistencia: Optional[float] = Field(None, ge=0, le=100, description="Asistencia (%)")
    edad: Optional[int] = Field(None, ge=15, le=70, description="Edad del estudiante")
    sexo: Optional[str] = Field(None, description="Sexo (M/F/Otro)")
    asignatura: Optional[str] = Field(None, description="Asignatura principal")
    establecimiento: Optional[str] = Field(None, description="Establecimiento educacional")
    a√±o: Optional[int] = Field(None, ge=2020, le=2030, description="A√±o acad√©mico")

class PredictionRequest(BaseModel):
    """Solicitud de predicci√≥n."""
    payload: StudentData

class PredictionResponse(BaseModel):
    """Respuesta de predicci√≥n."""
    riesgo_desercion: float = Field(..., ge=0, le=1, description="Probabilidad de deserci√≥n (0-1)")
    nivel_riesgo: str = Field(..., description="BAJO, MEDIO o ALTO")
    recomendacion: str = Field(..., description="Recomendaci√≥n textual")
    confianza: str = Field(..., description="Nivel de confianza de la predicci√≥n")

class CoachRequest(BaseModel):
    """Solicitud de coaching con LLM."""
    student_data: Dict[str, Any]
    question: str = Field(..., description="Pregunta del estudiante o docente")
    context: Optional[str] = Field(None, description="Contexto adicional")

class CoachResponse(BaseModel):
    """Respuesta de coaching."""
    answer: str = Field(..., description="Respuesta del coach virtual")
    riesgo_detectado: Optional[float] = Field(None, description="Riesgo detectado si aplica")

# === ENDPOINTS ===

@app.get("/")
async def root():
    """Endpoint ra√≠z con informaci√≥n de la API."""
    return {
        "message": "API de Predicci√≥n de Deserci√≥n Estudiantil - Duoc UC",
        "version": "1.0.0",
        "status": "online",
        "model_loaded": model is not None,
        "endpoints": {
            "GET /": "Informaci√≥n de la API",
            "GET /health": "Estado de la API y modelo",
            "POST /predict": "Predicci√≥n de riesgo de deserci√≥n",
            "POST /coach": "Coach virtual con LLM (requiere OpenAI API key)",
            "GET /threshold": "Obtener threshold actual",
            "GET /metrics": "M√©tricas del modelo",
            "GET /docs": "Documentaci√≥n interactiva Swagger"
        }
    }

@app.get("/health")
async def health():
    """Verifica el estado de la API y el modelo."""
    return {
        "status": "healthy",
        "model": {
            "loaded": model is not None,
            "path": str(MODEL_PATH),
            "exists": MODEL_PATH.exists(),
            "features_count": len(model.feature_names) if model else 0
        },
        "services": {
            "openai_coach": "available" if os.getenv("OPENAI_API_KEY") else "not_configured",
            "rag": "available" if rag and rag.bm25 else "not_available"
        }
    }

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """Predice el riesgo de deserci√≥n de un estudiante."""
    if model is None:
        raise HTTPException(
            status_code=503,
            detail="Modelo no disponible. Ejecuta 'python src/train.py' para entrenar el modelo."
        )
    
    try:
        # Convertir a dict
        data_dict = request.payload.dict(exclude_none=True)
        
        if not data_dict:
            raise HTTPException(
                status_code=400,
                detail="Debe proporcionar al menos un campo de datos del estudiante"
            )
        
        df = pd.DataFrame([data_dict])
        X = create_features(df)
        
        # Calcular confianza
        campos_disponibles = len(data_dict)
        campos_totales = 7  # promedio, asistencia, edad, sexo, asignatura, establecimiento, a√±o
        confianza_pct = campos_disponibles / campos_totales
        
        if confianza_pct > 0.7:
            confianza = "ALTA"
        elif confianza_pct > 0.4:
            confianza = "MEDIA"
        else:
            confianza = "BAJA"
        
        # Predecir
        prob = float(model.predict_proba(X)[0])
        threshold = current_threshold()
        
        # Clasificar nivel
        if prob >= threshold:
            nivel = "ALTO"
            recomendacion = (
                "üö® ALERTA: Riesgo alto de deserci√≥n - Acci√≥n inmediata requerida\n\n"
                "Plan de intervenci√≥n urgente:\n"
                "1. Entrevista individual con el estudiante (esta semana)\n"
                "2. Evaluar situaci√≥n personal/familiar/econ√≥mica\n"
                "3. Plan de intervenci√≥n personalizado con metas claras\n"
                "4. Seguimiento semanal obligatorio\n"
                "5. Coordinaci√≥n con Bienestar Estudiantil\n"
                "6. Considerar opciones de apoyo financiero/becas\n"
                "7. Vincular con tutor√≠as acad√©micas especializadas"
            )
        elif prob >= 0.5:
            nivel = "MEDIO"
            recomendacion = (
                "‚ö†Ô∏è Riesgo medio de deserci√≥n. "
                "Recomendaciones:\n"
                "‚Ä¢ Reuni√≥n con tutor acad√©mico para identificar causas\n"
                "‚Ä¢ Plan de mejora en asistencia y/o notas\n"
                "‚Ä¢ Apoyo psicopedag√≥gico si es necesario\n"
                "‚Ä¢ Seguimiento quincenal del progreso"
            )
        else:
            nivel = "BAJO"
            recomendacion = (
                "‚úÖ Bajo riesgo de deserci√≥n. "
                "Mantener seguimiento regular y reforzar h√°bitos positivos de estudio."
            )
        
        return PredictionResponse(
            riesgo_desercion=prob,
            nivel_riesgo=nivel,
            recomendacion=recomendacion,
            confianza=confianza
        )
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500, 
            detail=f"Error en predicci√≥n: {str(e)}"
        )

def sanitize_for_api(text: str) -> str:
    """Normaliza texto para evitar errores de encoding."""
    import unicodedata
    text = unicodedata.normalize('NFKD', text)
    text = text.encode('ascii', 'ignore').decode('ascii')
    return text

@app.post("/coach", response_model=CoachResponse)
async def coach(request: CoachRequest):
    """Coach virtual con LLM."""
    print(f"üîç DEBUG /coach - Iniciando request")
    
    # Verificar API key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise HTTPException(
            status_code=503,
            detail="OpenAI API key no configurada. A√±ade OPENAI_API_KEY al archivo .env"
        )
    
    print(f"üîç DEBUG - API key length: {len(api_key)}")
    print(f"üîç DEBUG - API key starts with 'sk-': {api_key.startswith('sk-')}")
    
    # Verificar que es ASCII puro
    try:
        api_key.encode('ascii')
        print(f"‚úÖ DEBUG - API key es ASCII v√°lido")
    except UnicodeEncodeError as e:
        print(f"‚ùå DEBUG - API key contiene caracteres no-ASCII: {e}")
        raise HTTPException(
            status_code=503,
            detail=f"OpenAI API key tiene caracteres inv√°lidos. Regener√° la key desde platform.openai.com"
        )
    
    try:
        from openai import OpenAI
        
        print(f"üîç DEBUG - Inicializando cliente OpenAI...")
        client = OpenAI(api_key=api_key)
        print(f"‚úÖ DEBUG - Cliente OpenAI inicializado")
        
        # Predecir riesgo si hay datos
        riesgo = None
        if model and request.student_data:
            try:
                print(f"üîç DEBUG - Calculando riesgo con datos: {list(request.student_data.keys())}")
                df = pd.DataFrame([request.student_data])
                X = create_features(df)
                riesgo = float(model.predict_proba(X)[0])
                print(f"‚úÖ DEBUG - Riesgo calculado: {riesgo:.3f}")
            except Exception as e:
                print(f"‚ö†Ô∏è No se pudo calcular riesgo en /coach: {e}")
                import traceback
                traceback.print_exc()
        
        # Sanitizar inputs
        print(f"üîç DEBUG - Sanitizando question: {request.question[:50]}...")
        safe_question = sanitize_for_api(request.question)
        safe_context = sanitize_for_api(request.context or "")
        
        # Buscar contexto RAG
        rag_context = ""
        if rag and rag.bm25 is not None:
            try:
                print(f"üîç DEBUG - Buscando contexto RAG...")
                query_parts = [safe_question]
                if request.student_data.get("promedio"):
                    query_parts.append(f"promedio {request.student_data['promedio']}")
                if request.student_data.get("asistencia"):
                    query_parts.append(f"asistencia {request.student_data['asistencia']}")
                
                query = " ".join(query_parts)
                results = rag.search(query, top_k=3)
                
                if results:
                    formatted = rag.format_context(results)
                    rag_context = f"\n\nContexto de datos historicos:\n{sanitize_for_api(formatted)}"
                    print(f"‚úÖ DEBUG - RAG context generado ({len(rag_context)} chars)")
            except Exception as e:
                print(f"‚ö†Ô∏è Error en busqueda RAG: {e}")
                import traceback
                traceback.print_exc()
        
        # Construir prompt
        context_str = f"\nContexto adicional: {safe_context}" if safe_context else ""
        riesgo_str = ""
        if riesgo is not None:
            thr = current_threshold()
            nivel = "ALTO" if riesgo >= thr else "MEDIO" if riesgo >= 0.5 else "BAJO"
            riesgo_str = f"\n\nRiesgo de desercion detectado: {riesgo:.1%} ({nivel})"
        
        # Sanitizar student_data
        safe_student_data = {}
        for k, v in request.student_data.items():
            if isinstance(v, str):
                safe_student_data[k] = sanitize_for_api(v)
            else:
                safe_student_data[k] = v
        
        system_prompt = """Eres un coach academico experto de Duoc UC especializado en prevencion de desercion estudiantil.

Tu rol es:
1. Brindar apoyo emocional y motivacional con empatia
2. Sugerir estrategias de estudio y organizacion concretas
3. Identificar recursos institucionales disponibles (tutorias, becas, apoyo psicologico)
4. Usar datos historicos de estudiantes similares para contextualizar tus recomendaciones
5. Ofrecer consejos practicos y accionables

Principios:
- Ser empatico y comprensivo
- Ofrecer soluciones realistas y alcanzables
- Enfocarte en fortalezas del estudiante
- Promover autonomia y autorregulacion
- Conectar con recursos institucionales cuando sea necesario
- Citar datos historicos cuando sea relevante

Responde de forma concreta, orientada a la accion y sin tecnicismos innecesarios."""
        
        user_prompt = f"""Pregunta del estudiante/docente: {safe_question}

Datos del estudiante: {safe_student_data}{context_str}{riesgo_str}{rag_context}

Por favor, proporciona una respuesta util, personalizada y empatica."""
        
        print(f"üîç DEBUG - User prompt length: {len(user_prompt)}")
        print(f"üîç DEBUG - Llamando OpenAI API (model: {os.getenv('LLM_MODEL', 'gpt-4o-mini')})...")
        
        response = client.chat.completions.create(
            model=os.getenv("LLM_MODEL", "gpt-4o-mini"),
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=800
        )
        
        print(f"‚úÖ DEBUG - OpenAI API respondi√≥ correctamente")
        answer = response.choices[0].message.content
        
        return CoachResponse(
            answer=answer,
            riesgo_detectado=riesgo
        )
    
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        print("\n" + "="*60)
        print("‚ùå ERROR COMPLETO EN /coach:")
        print("="*60)
        traceback.print_exc()
        print("="*60 + "\n")
        raise HTTPException(
            status_code=500, 
            detail=f"Error en coaching: {str(e)}"
        )

@app.get("/threshold")
async def get_threshold():
    """Obtiene el threshold actual."""
    return {
        "threshold": current_threshold(),
        "description": "Umbral para clasificar riesgo ALTO vs MEDIO"
    }

@app.post("/threshold")
async def update_threshold(threshold: float):
    """Actualiza el threshold din√°micamente."""
    global THRESHOLD_OVERRIDE
    if not 0.0 <= threshold <= 1.0:
        raise HTTPException(status_code=400, detail="Threshold debe estar entre 0.0 y 1.0")
    THRESHOLD_OVERRIDE = threshold
    return {
        "threshold": threshold,
        "message": f"Threshold actualizado a {threshold:.3f}"
    }

@app.get("/metrics")
async def get_metrics():
    """Obtiene m√©tricas del modelo."""
    if not METRICS_PATH.exists():
        return {
            "roc_auc": 0.0,
            "f1_opt": 0.0,
            "precision_opt": 0.0,
            "recall_opt": 0.0,
            "threshold_opt": current_threshold()
        }
    
    try:
        with open(METRICS_PATH, 'r') as f:
            metrics = json.load(f)
        return metrics
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error leyendo m√©tricas: {e}")
